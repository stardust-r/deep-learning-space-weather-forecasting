{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sweep_ensemble_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble utils for WandB Sweeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per run, wandb stores pred_test and pred_valid pickle files containing:\n",
    "* preds,targs,inp,losses,preds_denorm,targs_denorm,inp_denorm,pred_date\n",
    "\n",
    "Per sweep, per run need to access these predictions to be ensembled. WandB API: \n",
    "* https://docs.wandb.com/library/reference/wandb_api\n",
    "* https://docs.wandb.com/library/api\n",
    "* https://docs.wandb.ai/library/public-api-guide\n",
    "* https://docs.wandb.ai/ref/public-api\n",
    "\n",
    "Need to ensemble these predictions calculate mean/median and variance as an uncertainty on the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pathlib\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from lib.read_data import *\n",
    "from lib.stats_utils import cErrorMetrics, cStationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# careful, they change things a lot...\n",
    "#!pip3 install --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb, version 0.10.20\r\n"
     ]
    }
   ],
   "source": [
    "!wandb --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "#!wandb login <add your key here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from WandB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fdownload_wandb_files(api, entity, project, sweep_ids, datadirs, wandbfname=\"preds_test_fname\"):\n",
    "    \"\"\"\n",
    "    download files with fname for all runs associated with list of sweep_ids into datadirs\n",
    "    \n",
    "    output:\n",
    "    data[run_id] = [path, run.config]\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    for i in range(len(sweep_ids)):\n",
    "        sweep = api.sweep(\"{}/{}/{}\".format(entity, project, sweep_ids[i]))\n",
    "        print(\"Sweep: \", sweep.config[\"name\"])\n",
    "\n",
    "        datadir = pathlib.Path(datadirs[i])\n",
    "        datadir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for run in sweep.runs:\n",
    "            run_id = run.id\n",
    "\n",
    "            # fname on wandb api same for each run, need to rename with run_id\n",
    "            fname_todownload = run.config[wandbfname]#.split(\"/\")[1]\n",
    "            fname_downloaded = \"{}_{}.{}\".format(fname_todownload.split(\".\")[0], run_id, fname_todownload.split(\".\")[1])\n",
    "\n",
    "            # download (if doesn't already exist) and rename\n",
    "            if not (datadir/fname_downloaded).is_file():\n",
    "                file = run.file(fname_todownload)\n",
    "                print(\"{} downloading {}...\".format(run_id, fname_todownload))\n",
    "                file.download(replace=False, root=datadir)\n",
    "                (datadir/fname_todownload).rename(datadir/fname_downloaded)\n",
    "            else:\n",
    "                print(\"{} already downloaded.\".format(fname_downloaded))\n",
    "                \n",
    "            # store location of file and run info\n",
    "            data[run_id] = [datadir/fname_downloaded, run.config]\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fget_pickled(sweeps, datadir, entity, project, pklname=\"models/preds_test.pickle\", \n",
    "                 download=True, sweep_type=\"txt\"):\n",
    "    \"\"\"\n",
    "    download pickle files associated with runs in sweeps\n",
    "    read data into dictionary first broken down by horizon, then indiviual runs\n",
    "    \n",
    "    sweep_type: \"api\" or \"txt\" [for manual .txt files with sweep run ids]\n",
    "    sweeps == list of sweep ids or list of paths/filenames containing run ids\n",
    "    \"\"\"\n",
    "    # path to download files to\n",
    "    datadir = Path(datadir)\n",
    "    datadir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    api = wandb.Api()\n",
    "\n",
    "    data = {}\n",
    "    for sweep_i in sweeps:\n",
    "        \n",
    "        # case of wandb api working correctly:\n",
    "        if sweep_type == \"api\":\n",
    "            sweep = api.sweep(\"{}/{}/{}\".format(entity, project, sweep_i))\n",
    "            runs  = sweep.runs\n",
    "            lrun  = len(runs)\n",
    "            \n",
    "        # case of txt files containing list of run_ids:\n",
    "        elif sweep_type == \"txt\":\n",
    "            df = pd.read_csv(sweep_i, delimiter=\", \")\n",
    "            run_ids = df[\"ID\"].to_numpy().flatten()\n",
    "            horizon = df[\"H\"].to_numpy().flatten()\n",
    "            lrun = len(run_ids)\n",
    "        \n",
    "        print(sweep_i, lrun)\n",
    "\n",
    "        for i in range(lrun):\n",
    "            \n",
    "            if sweep_type == \"api\":\n",
    "                run = runs[i]\n",
    "                run_id = run.id\n",
    "                h = run.config[\"horizon\"]\n",
    "                \n",
    "            elif sweep_type == \"txt\":\n",
    "                run_id = run_ids[i]\n",
    "                # need access to run.config to get horizon (this is slow...)\n",
    "                #run = api.run(\"{}/{}/{}\".format(entity, project, run_id))\n",
    "                h = horizon[i]\n",
    "\n",
    "            # need to change name to include run_id or will overwrite\n",
    "            fname_todownload = pklname\n",
    "            fname_downloaded = \"{}_{}.{}\".format(fname_todownload.split(\".\")[0], run_id, fname_todownload.split(\".\")[1])\n",
    "\n",
    "            # download pickle file (if doesn't already exist)\n",
    "            if download:\n",
    "                if not (datadir/fname_downloaded).is_file():\n",
    "                    file = run.file(fname_todownload)\n",
    "                    print(\"{} downloading {}...\".format(run_id, fname_todownload))\n",
    "                    file.download(replace=False, root=datadir)\n",
    "                    (datadir/fname_todownload).rename(datadir/fname_downloaded)\n",
    "                else:\n",
    "                    print(\"{} already downloaded.\".format(fname_downloaded))\n",
    "\n",
    "            # read in pickle\n",
    "            with open(datadir/fname_downloaded, 'rb') as handle:\n",
    "                d = pickle.load(handle)\n",
    "\n",
    "            # store by horizon, run_id\n",
    "            try:\n",
    "                data[h][run_id] = d\n",
    "            except KeyError:\n",
    "                data[h] = {}\n",
    "                data[h][run_id] = d\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity  = \"stardust-r\"\n",
    "project = \"deep-learning-space-weather-forecasting\"\n",
    "\n",
    "# wandb sweep ids\n",
    "#sweeps = [\"inztzkl4\", \"607ppbji\", \"9ihcleuh\", \"2ajetr8i\"]\n",
    "\n",
    "# path to manual id text files\n",
    "sweeps = [\"./wandb_ensemble/ensemble/ensembleH3.txt\", \"./wandb_ensemble/ensemble/ensembleH5H7.txt\", \n",
    "          \"./wandb_ensemble/ensemble/ensembleH10H14.txt\", \"./wandb_ensemble/ensemble/ensembleH21H27.txt\"]\n",
    "\n",
    "# path to downloaded sweep run files\n",
    "datadir = \"../data/wandb_ensemble/ensemble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./wandb_ensemble/ensemble/ensembleH3.txt 90\n",
      "./wandb_ensemble/ensemble/ensembleH5H7.txt 180\n",
      "./wandb_ensemble/ensemble/ensembleH10H14.txt 180\n",
      "./wandb_ensemble/ensemble/ensembleH21H27.txt 180\n",
      "CPU times: user 403 ms, sys: 2.66 s, total: 3.07 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_valid = fget_pickled(sweeps, datadir, entity, project, pklname=\"models/preds_test.pickle\", \n",
    "                          download=False, sweep_type=\"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./wandb_ensemble/ensemble/ensembleH3.txt 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./wandb_ensemble/ensemble/ensembleH5H7.txt 180\n",
      "./wandb_ensemble/ensemble/ensembleH10H14.txt 180\n",
      "./wandb_ensemble/ensemble/ensembleH21H27.txt 180\n",
      "CPU times: user 2.39 s, sys: 12 s, total: 14.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for now this is not logged with wandb: must be manually generated by downloading model file and applying to training data\n",
    "data_train = fget_pickled(sweeps, datadir, entity, project, pklname=\"models/preds_train.pickle\", \n",
    "                          download=False, sweep_type=\"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preds': array([[0.09384836, 0.09275597, 0.09365283],\n",
       "        [0.09831063, 0.09721904, 0.09787896],\n",
       "        [0.10078903, 0.09968247, 0.10018463],\n",
       "        ...,\n",
       "        [0.11686298, 0.11467203, 0.11406119],\n",
       "        [0.11711943, 0.11463648, 0.1134624 ],\n",
       "        [0.11596964, 0.11376598, 0.11256385]], dtype=float32),\n",
       " 'targs': array([[0.10556812, 0.10712267, 0.1079706 ],\n",
       "        [0.10712267, 0.1079706 , 0.10570944],\n",
       "        [0.1079706 , 0.10570944, 0.10556812],\n",
       "        ...,\n",
       "        [0.12422272, 0.1240814 , 0.12323347],\n",
       "        [0.1240814 , 0.12323347, 0.11899378],\n",
       "        [0.12323347, 0.11899378, 0.11701526]]),\n",
       " 'inp': array([[0.10825325, 0.10839457, 0.10924251, ..., 0.09821933, 0.09836066,\n",
       "         0.1004805 ],\n",
       "        [0.10839457, 0.10924251, 0.1079706 , ..., 0.09836066, 0.1004805 ,\n",
       "         0.10556812],\n",
       "        [0.10924251, 0.1079706 , 0.10811193, ..., 0.1004805 , 0.10556812,\n",
       "         0.10712267],\n",
       "        ...,\n",
       "        [0.11644997, 0.116026  , 0.11517807, ..., 0.12210288, 0.12351611,\n",
       "         0.12394008],\n",
       "        [0.116026  , 0.11517807, 0.11772188, ..., 0.12351611, 0.12394008,\n",
       "         0.12422272],\n",
       "        [0.11517807, 0.11772188, 0.11560204, ..., 0.12394008, 0.12422272,\n",
       "         0.1240814 ]]),\n",
       " 'losses': array([91.58657861, 42.48662227, 19.5074303 , ..., 37.85825361,\n",
       "        25.53115709, 16.67459044]),\n",
       " 'preds_denorm': array([[66.4071  , 65.634125, 66.26874 ],\n",
       "        [69.564606, 68.79219 , 69.259155],\n",
       "        [71.31831 , 70.53531 , 70.89065 ],\n",
       "        ...,\n",
       "        [82.69224 , 81.14193 , 80.709694],\n",
       "        [82.87371 , 81.11677 , 80.285995],\n",
       "        [82.06012 , 80.50081 , 79.65018 ]], dtype=float32),\n",
       " 'targs_denorm': array([[74.7, 75.8, 76.4],\n",
       "        [75.8, 76.4, 74.8],\n",
       "        [76.4, 74.8, 74.7],\n",
       "        ...,\n",
       "        [87.9, 87.8, 87.2],\n",
       "        [87.8, 87.2, 84.2],\n",
       "        [87.2, 84.2, 82.8]]),\n",
       " 'inp_denorm': array([[76.6, 76.7, 77.3, ..., 69.5, 69.6, 71.1],\n",
       "        [76.7, 77.3, 76.4, ..., 69.6, 71.1, 74.7],\n",
       "        [77.3, 76.4, 76.5, ..., 71.1, 74.7, 75.8],\n",
       "        ...,\n",
       "        [82.4, 82.1, 81.5, ..., 86.4, 87.4, 87.7],\n",
       "        [82.1, 81.5, 83.3, ..., 87.4, 87.7, 87.9],\n",
       "        [81.5, 83.3, 81.8, ..., 87.7, 87.9, 87.8]]),\n",
       " 'pred_date': array(['2006-10-21', '2006-10-22', '2006-10-23', ..., '2020-12-26',\n",
       "        '2020-12-27', '2020-12-28'], dtype='<U10')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid[3][\"t8r3v9or\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 7, 10, 14, 21, 27]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons = list(sorted(data_valid.keys()))\n",
    "horizons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fget_preds(subdict, limit_date=False, lcompdate=None, ucompdate=None):\n",
    "    \"\"\"\n",
    "    stack predictions over ensemble runs\n",
    "    get predictions and targets from runs\n",
    "    shape: (90, 20729, 3) (n_ensemble_runs, n_windows, H)\n",
    "    \n",
    "    limit_date to crop for comparison with cls, esa etc.\n",
    "    \"\"\"\n",
    "    # shorter lookbacks have more predictions\n",
    "    # need to ensure all predictions are of same length and are combining the right set of predictions\n",
    "    common_idx = []\n",
    "    for run_id in subdict.keys():\n",
    "        common_idx.append(len(subdict[run_id][\"pred_date\"]))\n",
    "    idx = min(common_idx)\n",
    "\n",
    "    # get common targets and prediction dates\n",
    "    keys  = list(subdict.keys())\n",
    "    targs = subdict[keys[0]][\"targs_denorm\"][-idx:]\n",
    "    epoch = subdict[keys[0]][\"pred_date\"][-idx:]\n",
    "    \n",
    "    if limit_date:\n",
    "        try:\n",
    "            larg = np.argwhere(epoch==lcompdate)[0][0]\n",
    "        except IndexError:\n",
    "            larg = 0\n",
    "        try:\n",
    "            uarg = np.argwhere(epoch==ucompdate)[0][0] + 1\n",
    "        except IndexError:\n",
    "            uarg = -1\n",
    "        targs = targs[larg:uarg]\n",
    "        epoch = epoch[larg:uarg]\n",
    "    \n",
    "    # get predictions for each run\n",
    "    preds = []\n",
    "    for run_id in subdict.keys():\n",
    "        if limit_date:\n",
    "            preds.append(subdict[run_id][\"preds_denorm\"][-idx:][larg:uarg])\n",
    "        else:\n",
    "            preds.append(subdict[run_id][\"preds_denorm\"][-idx:])\n",
    "    print(np.array(preds).shape, epoch[0], epoch[-1])\n",
    "    \n",
    "    return np.array(epoch), np.array(preds), np.array(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fensemble(preds_valid, mode=\"mean\"):\n",
    "    \"\"\"\n",
    "    simple mean/median ensemble, std over ensemble\n",
    "    \"\"\"\n",
    "    # reshape\n",
    "    stack = np.dstack(preds_valid)\n",
    "    \n",
    "    if mode == \"mean\":\n",
    "        ensemble_preds = np.mean(stack, axis=2)\n",
    "    elif mode == \"median\":\n",
    "        ensemble_preds = np.median(stack, axis=2)\n",
    "  \n",
    "    # variance in ensemble\n",
    "    ensemble_std = np.std(stack, axis=2)\n",
    "    #print(ensemble_std.shape)\n",
    "        \n",
    "    return ensemble_preds, ensemble_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fensemble_linear_regression(preds_valid, targs_valid, preds_train, targs_train):\n",
    "    \"\"\"\n",
    "    learn linear regression coefficients from training data (one for each day over horizon, H)\n",
    "    apply to combine validation data\n",
    "    \n",
    "    X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "    # y = 1 * x_0 + 2 * x_1 + 3\n",
    "    y = np.dot(X, np.array([1, 2])) + 3\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    reg.coef_ = array([1., 2.])\n",
    "    reg.predict(np.array([[3, 5]])) = array([16.])\n",
    "    \"\"\"\n",
    "    ensemble_preds = []\n",
    "    \n",
    "    H = preds_valid.shape[2]\n",
    "\n",
    "    for h in range(H):\n",
    "        # should be 90 (n_ensemble_runs) coefficients\n",
    "        X = preds_train[:,:,h].T\n",
    "        y = targs_train[:,h]\n",
    "        reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "\n",
    "        X_valid = preds_valid[:,:,h].T\n",
    "        y_valid = targs_valid[:,h]\n",
    "        #print(reg.predict(X_valid), np.dot(X_valid, reg.coef_) + reg.intercept_, y_valid) # np.sum(np.multiply(X[-1], reg.coef_)) + intercept\n",
    "        \n",
    "        print(h, reg.score(X, y), reg.score(X_valid, y_valid))\n",
    "        \n",
    "        ensemble_preds.append(np.dot(X_valid, reg.coef_) + reg.intercept_)\n",
    "        \n",
    "    # not yet implemented with uncertainty\n",
    "\n",
    "    return np.stack(ensemble_preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fensemble_boosting_regressor(preds_valid, targs_valid, preds_train, targs_train, alpha=0.9):\n",
    "    \"\"\"\n",
    "    Learn combination of ensemble members from training data using Gradient Boosting Regression\n",
    "    Also provides prediction intervals (using quantile regression)\n",
    "    alpha = % prediction interval\n",
    "    \n",
    "    https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html\n",
    "    https://towardsdatascience.com/how-to-generate-prediction-intervals-with-scikit-learn-and-python-ab3899f992ed\n",
    "    \"\"\"\n",
    "    ensemble_preds = []\n",
    "    ensemble_lower = []\n",
    "    ensemble_upper = []\n",
    "    \n",
    "    H = preds_valid.shape[2]\n",
    "\n",
    "    # run for each day over horizon\n",
    "    for h in range(H):\n",
    "        \n",
    "        X_train = preds_train[:,:,h].T\n",
    "        y_train = targs_train[:,h]\n",
    "        X_test = preds_valid[:,:,h].T\n",
    "        y_test = targs_valid[:,h]\n",
    "        \n",
    "        upper_model = GradientBoostingRegressor(loss=\"quantile\", alpha=alpha)\n",
    "        mid_model   = GradientBoostingRegressor(loss=\"ls\")\n",
    "        lower_model = GradientBoostingRegressor(loss=\"quantile\", alpha=(1.0-alpha))                 \n",
    "\n",
    "        # fit models\n",
    "        lower_model.fit(X_train, y_train)\n",
    "        mid_model.fit(X_train, y_train)\n",
    "        upper_model.fit(X_train, y_train)\n",
    "        \n",
    "        # store predictions\n",
    "        ensemble_preds.append(mid_model.predict(X_test))\n",
    "        ensemble_lower.append(lower_model.predict(X_test))\n",
    "        ensemble_upper.append(upper_model.predict(X_test))\n",
    "\n",
    "    return np.stack(ensemble_preds).T, np.stack(ensemble_lower).T, np.stack(ensemble_upper).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon: 3\n",
      "(90, 20729, 3) 1950-01-19 2006-10-20\n",
      "(90, 5183, 3) 2006-10-21 2020-12-28\n",
      "(5183, 3) (5183, 3)\n",
      "Horizon: 5\n",
      "(90, 20718, 5) 1950-01-31 2006-10-21\n",
      "(90, 5180, 5) 2006-10-22 2020-12-26\n",
      "(5180, 5) (5180, 5)\n",
      "Horizon: 7\n",
      "(90, 20707, 7) 1950-02-12 2006-10-22\n",
      "(90, 5177, 7) 2006-10-23 2020-12-24\n",
      "(5177, 7) (5177, 7)\n",
      "Horizon: 10\n",
      "(90, 20690, 10) 1950-03-02 2006-10-23\n",
      "(90, 5173, 10) 2006-10-24 2020-12-21\n",
      "(5173, 10) (5173, 10)\n",
      "Horizon: 14\n",
      "(90, 20668, 14) 1950-03-26 2006-10-25\n",
      "(90, 5167, 14) 2006-10-26 2020-12-17\n",
      "(5167, 14) (5167, 14)\n",
      "Horizon: 21\n",
      "(90, 20628, 21) 1950-05-07 2006-10-27\n",
      "(90, 5158, 21) 2006-10-28 2020-12-10\n",
      "(5158, 21) (5158, 21)\n",
      "Horizon: 27\n",
      "(90, 20595, 27) 1950-06-12 2006-10-30\n",
      "(90, 5149, 27) 2006-10-31 2020-12-04\n",
      "(5149, 27) (5149, 27)\n"
     ]
    }
   ],
   "source": [
    "limit_date = False\n",
    "lcompdate = None\n",
    "ucompdate = None\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for horizon in horizons:\n",
    "    print(\"Horizon: {}\".format(horizon))\n",
    "    \n",
    "    # get training (if learning weights) and validation predictions and targets\n",
    "    epoch_train, preds_train, targs_train = fget_preds(data_train[horizon])\n",
    "    epoch_valid, preds_valid, targs_valid = fget_preds(data_valid[horizon], limit_date, lcompdate, ucompdate)\n",
    "    \n",
    "    ensemble_preds, ensemble_std = fensemble(preds_valid, mode=\"mean\")\n",
    "    print(ensemble_preds.shape, ensemble_std.shape)\n",
    "    \n",
    "    # ensemble and store predictions and uncertainty\n",
    "    predictions[horizon] = [epoch_valid, targs_valid, ensemble_preds, ensemble_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble_preds_mean_None-None.pickle\n",
      "Pickle file does not exist.\n",
      "CPU times: user 0 ns, sys: 1.45 ms, total: 1.45 ms\n",
      "Wall time: 828 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "limit_date = False\n",
    "lcompdate = None\n",
    "ucompdate = None\n",
    "\n",
    "mode = \"mean\" # \"median\", \"boosting_regressor\"\n",
    "\n",
    "# read from pickled file (need for \"boosting_regressor\" as slow to train)\n",
    "use_pickle = False\n",
    "fname = \"./wandb_ensemble/ensemble/ensemble_preds_{}_{}-{}.pickle\".format(mode, lcompdate, ucompdate)\n",
    "\n",
    "if use_pickle:\n",
    "    try:\n",
    "        with open(fname, 'rb') as handle:\n",
    "            predictions = pickle.load(handle)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Pickle file does not exist.\")\n",
    "        use_pickle = False\n",
    "\n",
    "if not use_pickle:\n",
    "    predictions = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        print(\"Horizon: {}\".format(horizon))\n",
    "\n",
    "        # get training (if learning weights) and validation predictions and targets\n",
    "        epoch_train, preds_train, targs_train = fget_preds(data_train[horizon])\n",
    "        epoch_valid, preds_valid, targs_valid = fget_preds(data_valid[horizon], limit_date, lcompdate, ucompdate)\n",
    "\n",
    "        # ensemble and store predictions and uncertainty or prediction interval\n",
    "        if mode == \"boosting_regressor\"\n",
    "            ensemble_preds, ensemble_lower, ensemble_upper = fensemble_boosting_regressor(preds_valid, targs_valid, \n",
    "                                                                                          preds_train, targs_train, \n",
    "                                                                                          alpha=0.95)\n",
    "            predictions[horizon] = [epoch_valid, targs_valid, ensemble_preds, ensemble_lower, ensemble_upper]\n",
    "        else:\n",
    "            ensemble_preds, ensemble_std = fensemble(preds_valid, mode=mode)\n",
    "            predictions[horizon] = [epoch_valid, targs_valid, ensemble_preds, ensemble_std]\n",
    "\n",
    "    # if pickle does not already exist, generate\n",
    "    if not Path(fname).is_file():\n",
    "        with open(fname, 'wb') as handle:\n",
    "            pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean square error.\n",
    "    (from sklearn.metrics import mean_squared_error)\n",
    "    \"\"\"\n",
    "    # return np.sum( (np.array(y_true) - np.array(y_pred))**2 ) / len(y_true)\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def fmape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    mean_absolute_percentage_error.\n",
    "    (can cause division-by-zero errors)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def fcc_pearsonr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    pearson correlation coefficient\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pearsonr(y_true, y_pred)\n",
    "    except TypeError:\n",
    "        return pearsonr(y_true.flatten(), y_pred.flatten())\n",
    "    \n",
    "def frmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root mean square error.\n",
    "    (from sklearn.metrics import mean_squared_error)\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def fmae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    mean absolute error\n",
    "    \"\"\"\n",
    "    #return np.sum( np.abs(np.array(y_true) - np.array(y_pred)) ) / len(y_true)\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def fme(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    bias\n",
    "    see Liemohn 2018 (model - observed)\n",
    "    \"\"\"\n",
    "    return np.sum( np.array(y_pred) - np.array(y_true) ) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fmse_std(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean square error.\n",
    "    (from sklearn.metrics import mean_squared_error)\n",
    "    There mse stds are massive: would need to plot using rmse\n",
    "    \"\"\"\n",
    "    se = (np.array(y_true) - np.array(y_pred))**2\n",
    "    mse = np.mean(se)#, axis=0\n",
    "    sdse = np.std(se)#, axis=0\n",
    "    return sdse\n",
    "    \n",
    "def fmape_std(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    mean_absolute_percentage_error.\n",
    "    (can cause division-by-zero errors)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    ape = np.abs((y_true - y_pred) / y_true)\n",
    "    mape = np.mean(ape) * 100\n",
    "    sdape = np.std(ape) * 100\n",
    "    return sdape\n",
    "\n",
    "def fcc_pearsonr_std(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    pearson correlation coefficient\n",
    "    \"\"\"\n",
    "    return np.nan\n",
    "\n",
    "def frmse_std(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root mean square error.\n",
    "    (from sklearn.metrics import mean_squared_error)\n",
    "    \"\"\"\n",
    "    se = (np.array(y_true) - np.array(y_pred))**2\n",
    "    mse = np.mean(se)#, axis=0\n",
    "    sdse = np.std(se)#, axis=0\n",
    "    return np.sqrt(sdse)\n",
    "\n",
    "def fmae_std(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    mean absolute error\n",
    "    \"\"\"\n",
    "    ae = np.abs(np.array(y_true) - np.array(y_pred))\n",
    "    mae = np.mean(ae)#, axis=0\n",
    "    sdae = np.std(ae)#, axis=0\n",
    "    return sdae\n",
    "\n",
    "def fme_std(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    bias\n",
    "    see Liemohn 2018 (model - observed)\n",
    "    \"\"\"\n",
    "    e = np.array(y_pred) - np.array(y_true)\n",
    "    me = np.mean(e)#, axis=0\n",
    "    sde = np.std(e)#, axis=0\n",
    "    return sde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fget_metrics(y_pred, y_true):\n",
    "    return [fmse(y_true, y_pred), fmape(y_true, y_pred), fcc_pearsonr(y_true, y_pred)[0], \n",
    "            frmse(y_true, y_pred), fmae(y_true, y_pred), fme(y_true, y_pred)]\n",
    "\n",
    "def fget_metrics_std(y_pred, y_true):\n",
    "    return [fmse_std(y_true, y_pred), fmape_std(y_true, y_pred), fcc_pearsonr_std(y_true, y_pred), \n",
    "            frmse_std(y_true, y_pred), fmae_std(y_true, y_pred), fme_std(y_true, y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fget_external_forecasts(config):\n",
    "    \"\"\"\n",
    "    generate dataframe containing forecasts and \"truths\" for external sources\n",
    "    get persistence \n",
    "    \n",
    "    test:\n",
    "    #config = AttrDict()\n",
    "    #config.update(user_config)\n",
    "    #fget_external_forecasts(config)\n",
    "    \"\"\"\n",
    "    # ESA\n",
    "    if \"esa\" in config.data_comp:\n",
    "        dataobj_esa = cESA_SWE()\n",
    "        # read in archive data\n",
    "        df = dataobj_esa.fget_data(filenames=config.esa_archive_fname)[config.esa_archive_key]\n",
    "        df.set_index('ds', inplace=True)\n",
    "        udate_a = (dt.datetime.strptime(config.date_ulim, \"%Y-%m-%d\") + dt.timedelta(days=27)).strftime(\"%Y-%m-%d\")\n",
    "        df_lim = df[config.date_llim:udate_a]\n",
    "        #dfa_esa = dataobj_esa.finterpolate(df_lim, config.interp_freq)\n",
    "        df_daily = dataobj_esa.fget_daily(df_lim, config.get_daily_method)\n",
    "        dfa_esa  = dataobj_esa.fmissing_data(df_daily, config.missing_data_method)\n",
    "        # read in esa forecast data  \n",
    "        dff_esa = dataobj_esa.fget_data(filenames=config.esa_forecast_fname)[config.esa_forecast_key]\n",
    "        # add \"truth\" from archive to forecast\n",
    "        dff_comp_esa = dataobj_esa.fget_forecast_comp(dff_esa, dfa_esa, cname=\"y\")\n",
    "        \n",
    "        # rename columns\n",
    "        #dfa_esa.columns = ['gendate' , 'ds', 'y_esa_true'] \n",
    "        dff_comp_esa.columns = ['gendate' , 'ds', 'y_esa', 'y_esa_true']        \n",
    "        # Calculate persistence\n",
    "        #dff_comp_esa = dataobj_esa.fget_persistence(dfa_esa, 'y_esa_true', \"persistence_esa\")\n",
    "        dff_comp_esa = dataobj_esa.fget_persistence(dff_comp_esa, 'y_esa_true', \"persistence_esa\")        \n",
    "    \n",
    "    # CLS-CNES\n",
    "    if \"cls\" in config.data_comp:\n",
    "        dataobj_cls = cCLS_CNES()\n",
    "        # read in archive data and restrict to ds and key variable\n",
    "        # need to ensure upper date for archive is 30 days ahead of upper date of forecast gendate\n",
    "        udate_a = (dt.datetime.strptime(config.cls_forecast_udate, \"%Y-%m-%d\") + dt.timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "        dfa_cls = dataobj_cls.fget_archive_data(config.cls_datadir, config.cls_forecast_ldate, udate_a)\n",
    "        dfa_cls = dfa_cls[['ds',config.cls_key]]\n",
    "        dfa_cls = dfa_cls.set_index(\"ds\")\n",
    "        # read in forecast data and restrict to key variable\n",
    "        dff_cls = dataobj_cls.fget_forecast_data(config.cls_datadir, config.cls_forecast_ldate, config.cls_forecast_udate)\n",
    "\n",
    "        dff_cls = dff_cls[['gendate', 'ds', \"{}_c\".format(config.cls_key)]]\n",
    "        # add \"truth\" from archive to forecast\n",
    "        dff_comp_cls = dataobj_cls.fget_forecast_comp(dff_cls, dfa_cls, cname=config.cls_key)\n",
    "        \n",
    "        # rename columns\n",
    "        dff_comp_cls.columns = ['gendate' , 'ds', 'y_cls', 'y_cls_true']  \n",
    "        # Calculate persistence\n",
    "        dff_comp_cls = dataobj_cls.fget_persistence(dff_comp_cls, 'y_cls_true', \"persistence_cls\")\n",
    "        \n",
    "        # botch\n",
    "        # include esa persistence in cls only table\n",
    "        if \"esa\" not in config.data_comp:\n",
    "            dataobj_esa = cESA_SWE()\n",
    "            # read in archive data\n",
    "            df = dataobj_esa.fget_data(filenames=config.esa_archive_fname)[config.esa_archive_key]\n",
    "            df.set_index('ds', inplace=True)\n",
    "\n",
    "            ldate = (dt.datetime.strptime(config.cls_forecast_ldate, \"%Y-%m-%d\") - dt.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "            df_lim = df[ldate:udate_a] # hard code as takes 1 day later for some reason\n",
    "            #dfa_esa = dataobj_esa.finterpolate(df_lim, config.interp_freq)\n",
    "            df_daily = dataobj_esa.fget_daily(df_lim, config.get_daily_method)\n",
    "            dfa_esa  = dataobj_esa.fmissing_data(df_daily, config.missing_data_method)\n",
    "            # add \"truth\" from archive to forecast\n",
    "            dff_comp_cls1 = dataobj_cls.fget_forecast_comp(dff_cls, dfa_esa, cname=\"y_cls\")\n",
    "\n",
    "            dff_comp_cls1.columns = ['gendate' , 'ds', 'y_cls', 'y_esa_true']\n",
    "\n",
    "            # drop gendates that don't give full forcast (depends on horizon)\n",
    "            dff_comp_cls1 = dff_comp_cls1[dff_comp_cls1.groupby('gendate').gendate.transform('count')>=27].copy()\n",
    "\n",
    "            # Calculate persistence\n",
    "            dff_comp_cls1 = dataobj_cls.fget_persistence(dff_comp_cls1, 'y_esa_true', \"persistence_esa\")\n",
    "\n",
    "            dff_comp_cls = pd.merge(dff_comp_cls, dff_comp_cls1, on=['gendate', 'ds', 'y_cls'])\n",
    "            \n",
    "    \n",
    "    # COMBINE AND RETURN\n",
    "    if (\"esa\" in config.data_comp) and (\"cls\" in config.data_comp):\n",
    "        df_comp = pd.merge(dff_comp_esa, dff_comp_cls, on=['gendate', 'ds'])\n",
    "        return df_comp\n",
    "    elif \"esa\" in config.data_comp:\n",
    "        return dff_comp_esa\n",
    "    elif \"cls\" in config.data_comp:\n",
    "        return dff_comp_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fget_external_metrics(dff, config):\n",
    "    metrics = {}\n",
    "    metrics_std = {}\n",
    "    \n",
    "    if \"esa\" in config.data_comp:\n",
    "        metrics[\"ESA\"] = fget_metrics(dff.y_esa, dff.y_esa_true)\n",
    "        metrics_std[\"ESA\"] = fget_metrics_std(dff.y_esa, dff.y_esa_true)\n",
    "        \n",
    "    if \"cls\" in config.data_comp:\n",
    "        metrics[\"CLS\"] = fget_metrics(dff.y_cls, dff.y_cls_true)\n",
    "        metrics_std[\"CLS\"] = fget_metrics_std(dff.y_cls, dff.y_cls_true)\n",
    "    \n",
    "    metrics[\"PERSISTENCE\"] = fget_metrics(dff.persistence_esa, dff.y_esa_true)\n",
    "    metrics_std[\"PERSISTENCE\"] = fget_metrics_std(dff.persistence_esa, dff.y_esa_true)\n",
    "    #metrics[\"PERSISTENCE\"] = fget_metrics(dff.persistence_cls, dff.y_cls_true)\n",
    "    \n",
    "    return metrics, metrics_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_stats_utils.ipynb.\n",
      "Converted 02_plot_utils.ipynb.\n",
      "Converted 03_read_data.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_solar_flux_time_series_forecasting.ipynb.\n",
      "Converted 06_ensemble_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
